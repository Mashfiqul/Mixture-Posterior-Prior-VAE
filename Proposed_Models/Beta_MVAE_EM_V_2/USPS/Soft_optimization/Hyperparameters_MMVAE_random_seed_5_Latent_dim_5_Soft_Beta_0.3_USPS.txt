Dataset: USPS
--------------------------------------------
Model Name: MMVAE_random_seed_5_Latent_dim_5_Soft_Optimization_Beta_0.3_USPS_dataset
==================================================================
MMVAE_random_seed_5_Latent_dim_5_Soft_Optimization_Beta_0.3_USPS_dataset Part:
==================================================================
VAE Part:
==================================================================
Random Seed = 5
--------------------------------------------
Device = cuda:0
--------------------------------------------
Number of Epochs = 2000
--------------------------------------------
Learning Rate = 0.0001
--------------------------------------------
Step Size = 20
--------------------------------------------
Input Dimension = 256
--------------------------------------------
Encoder Hidden Dimension 1 = 500
--------------------------------------------
Encoder Hidden Dimension 2 = 500
--------------------------------------------
Encoder Hidden Dimension 3 = 2000
--------------------------------------------
Latent Dimension = 5
--------------------------------------------
Decoder Hidden Layer 1 = 2000
--------------------------------------------
Decoder Hidden Layer 2 = 500
--------------------------------------------
Decoder Hidden Layer 3 = 500
--------------------------------------------
Output Dimension = 256
--------------------------------------------
Weight Decay = 1e-05
--------------------------------------------
Batch Size (Training) = 100
--------------------------------------------
Batch Size (Test) = 100
--------------------------------------------
gamma = 0.9
--------------------------------------------
beta_1 = 0.3
==================================================================

GMM Part:
==================================================================
Number of Components= 10
--------------------------------------------
Covariance Matrix= full
--------------------------------------------
Number of Iterations= 20
--------------------------------------------
Epsilon = 1e-10
--------------------------------------------
Precision = 28
==================================================================

Early Stopping:
--------------------------------------------
Maximum Patience = 2001
--------------------------------------------
Best Test Loss = inf
--------------------------------------------
Patience Counters = 0
==================================================================

Loss Functions:
==================================================================
Decoder Loss (Training) = tensor([[-111.5524,  -78.9892, -148.5588, -107.7812, -114.1424, -137.8540,
         -106.6424,  -78.8163, -134.4004, -156.9243],
        [-110.1204,  -45.6271, -188.9016, -130.8884, -103.0592, -123.2535,
          -41.8231,  -44.9599,  -68.6866, -195.5448],
        [-191.4451,  -89.4474, -208.9740, -140.0672, -194.6670, -161.0125,
         -199.8194,  -95.7326, -171.1894, -219.2943],
        [-148.2012,  -74.9010, -218.5466, -149.6850, -194.8302, -152.7054,
         -174.4465,  -76.8491, -177.5762, -198.2077],
        [-104.4895,  -75.1069, -218.0270, -131.7152, -122.3768, -154.8832,
         -110.4418,  -75.7909, -126.0822, -216.6977],
        [-223.5097,  -93.1901, -242.3546, -210.8802, -245.9840, -174.9977,
         -274.5422,  -97.5366, -201.0795, -250.3302],
        [-134.1550,  -75.6743, -278.7191, -124.4427, -163.5971, -163.5271,
         -139.0954,  -74.5163, -180.5840, -246.1266],
        [-233.6743,  -96.4500, -255.8240, -191.2789, -218.6136, -186.8046,
         -215.5767, -117.5372, -140.4589, -264.2761],
        [-151.5841,  -72.5556, -189.5643, -141.5768, -172.4435, -138.0052,
         -128.2340,  -77.3552, -108.1629, -214.3540],
        [-140.5516,  -95.9487, -224.6657, -135.6796, -134.0869, -184.7523,
         -128.6693,  -95.8058, -183.5633, -192.3355],
        [-117.3073,  -72.2650, -250.7939, -147.7530, -137.0978, -176.6237,
         -107.0476,  -72.4203, -107.7089, -228.1401],
        [-204.5593,  -85.8780, -196.4196, -199.8118, -266.9926, -123.0448,
         -285.4625,  -80.4974, -411.9058, -206.7605],
        [-267.4584, -117.1391, -291.5161, -188.5301, -300.4498, -190.4197,
         -402.7209, -125.3954, -338.4277, -280.5427],
        [-168.0363,  -80.1320, -413.3762, -173.7979, -269.4340, -190.8830,
         -244.4747,  -77.7927, -321.1747, -248.2183],
        [ -84.9428,  -50.9955, -144.6355, -122.1854, -105.0168, -142.4416,
          -45.8649,  -54.5524,  -76.1703, -222.2346],
        [-132.6193,  -75.3068, -225.6512, -117.3356, -176.6238, -160.0387,
         -138.1451,  -72.7121, -210.1154, -234.9027],
        [-177.6396,  -87.9085, -399.6259, -165.8192, -252.2782, -226.0621,
         -242.3415,  -86.1478, -252.8498, -263.9003],
        [-193.2397,  -90.0250, -271.6514, -165.8382, -165.3173, -181.2038,
         -167.7823,  -91.9196, -169.0393, -205.1983],
        [-113.7926,  -54.0063, -136.4266, -119.8219, -137.6366, -118.7346,
          -83.9298,  -52.1929, -124.5174, -216.2751],
        [-251.7448, -127.0068, -299.8285, -198.1756, -199.4311, -128.7979,
         -259.7156, -129.3515, -254.5897, -311.4694],
        [-102.9684,  -44.9168, -190.6216, -137.3434, -111.9293, -141.8156,
          -42.2939,  -45.8092,  -54.3173, -280.9108],
        [-223.1716, -103.6450, -177.5543, -154.1137, -223.0331, -181.6904,
         -361.2845, -111.0405, -173.5243, -187.9332],
        [-179.2604,  -89.3824, -170.2362, -143.0512, -173.4496, -167.6811,
         -216.5094,  -91.3325, -162.3416, -174.3986],
        [ -96.5458,  -44.0253, -122.2947, -132.9308,  -92.6896, -122.4567,
          -40.1034,  -42.8987,  -63.7182, -265.1780],
        [-254.6840,  -97.9522, -389.2276, -253.4154, -223.6594, -143.0405,
         -262.7011, -104.1207, -269.1369, -423.3639],
        [-260.9042, -107.5561, -264.8688, -213.9888, -362.0436, -226.6278,
         -403.2921, -107.9261, -449.0595, -216.4467],
        [ -93.4093,  -44.8737, -142.8122, -127.2352, -100.1428,  -90.9104,
          -44.3651,  -45.6442,  -57.1330, -215.3802],
        [-157.6619,  -76.3389, -316.3422, -148.7927, -217.1116, -210.9328,
         -203.7578,  -75.1309, -200.1657, -206.9730],
        [-157.3943,  -77.3237, -209.2358, -152.5949, -191.9283, -160.5645,
         -202.3590,  -80.2763, -212.4651, -162.2535],
        [-210.7079, -101.7544, -220.4283, -131.4749, -212.0872, -206.8464,
         -300.9953, -101.5718, -181.9500, -180.3440],
        [-174.9285,  -98.6878, -157.3915, -145.7741, -169.9237, -177.5476,
         -219.9622, -103.1495, -135.9719, -183.2023],
        [-211.2466, -112.2129, -362.6656, -201.0193, -209.4468, -216.7963,
         -244.2987, -111.5168, -295.1319, -304.1940],
        [-217.8527, -103.6800, -194.9634, -173.8447, -197.0995, -179.0215,
         -343.8492, -113.3013, -162.6989, -228.9521],
        [-276.7196,  -93.6973, -313.9750, -198.2104, -348.3469, -271.9682,
         -475.3404,  -95.3798, -286.9370, -240.8971],
        [-202.7167,  -88.8883, -217.5535, -180.0197, -192.1480, -165.0839,
         -138.5969, -102.3172, -113.0077, -238.1341],
        [-168.4703,  -74.7025, -226.5571, -145.6815, -218.6601, -144.6472,
         -179.1140,  -73.2911, -331.2198, -273.8994],
        [-178.8946,  -92.4402, -192.6490, -150.2314, -163.2776, -169.6684,
         -171.7132, -100.7058, -139.4303, -217.0387],
        [-219.3985, -102.8095, -211.1744, -167.6346, -213.9181, -172.9659,
         -239.2924, -112.4895, -201.6667, -209.8944],
        [-225.9517, -102.2111, -294.6739, -186.7893, -236.4081, -180.1442,
         -219.8797, -128.4218, -142.6985, -262.5955],
        [ -84.6066,  -39.3266, -147.5499, -125.1105,  -84.3075, -140.6650,
          -37.9727,  -40.6549,  -62.2834, -266.6620],
        [-145.3331,  -90.8472, -207.5616, -158.7019, -177.4022, -148.3402,
         -143.4108,  -90.8225, -143.6144, -213.1875],
        [-155.6945,  -70.0502, -290.3707, -151.2219, -196.6078, -154.7995,
         -165.8899,  -68.0771, -158.1496, -237.9062],
        [-114.9193,  -49.5994, -171.1223, -120.3765, -100.9514, -127.1922,
          -64.9335,  -50.3031,  -89.9716, -228.1932],
        [-259.2166, -104.8329, -242.7108, -178.3236, -212.4070, -147.7568,
         -295.3315, -124.6914, -165.2314, -285.4153],
        [ -86.1925,  -43.0123, -144.0548, -149.8109,  -95.5794, -137.8985,
          -40.4362,  -42.4838,  -65.2735, -259.2386],
        [-247.9627,  -97.0654, -429.6674, -237.0618, -168.0731, -136.2808,
         -280.3420, -100.5397, -330.9963, -492.5770],
        [-156.0385,  -75.1726, -160.4877, -146.3148, -143.7883, -158.1588,
         -116.4640,  -82.9879,  -82.5605, -186.8171],
        [-193.0291,  -79.7488, -370.2839, -171.8761, -275.5770, -203.1355,
         -243.5857,  -78.7939, -345.7245, -256.2932],
        [-244.3374,  -88.1742, -357.5468, -206.5064, -374.2773, -239.1514,
         -352.6638,  -86.0127, -478.3182, -232.7509],
        [-106.3794,  -56.9550, -159.0400, -114.4245, -113.1539, -119.6041,
          -86.9806,  -57.7360, -140.4346, -250.4027],
        [-243.6589, -116.1884, -307.9136, -215.7910, -220.0534, -117.9662,
         -279.4013, -121.3083, -277.3459, -321.9840],
        [ -97.5329,  -48.2346, -142.9743, -130.5142,  -91.1420, -144.9642,
          -42.7597,  -47.8020,  -61.5324, -222.2902],
        [-195.4023,  -93.4386, -485.2994, -224.0247, -314.5413, -247.3348,
         -262.5984,  -91.5947, -365.1646, -276.0806],
        [-164.1921,  -86.3774, -204.1995, -146.1359, -171.2575, -172.6814,
         -143.1084,  -94.1051, -119.4857, -188.8627],
        [-123.5456,  -79.7512, -180.1274, -129.2777, -120.2350, -140.4141,
         -103.1071,  -79.3093, -141.1300, -182.8343],
        [-239.1531,  -99.5301, -174.5011, -152.6066, -216.7157, -160.2868,
         -337.7555, -107.2108, -160.0638, -222.5253],
        [-144.7358,  -81.3521, -388.1416, -190.4576, -250.2127, -205.7340,
         -220.5219,  -81.6226, -253.6476, -228.4995],
        [-114.4595,  -76.0166, -237.7348, -138.5904, -130.9417, -166.2349,
         -115.7079,  -77.5407, -133.5291, -246.0803],
        [-213.8641,  -83.3799, -203.5376, -122.5225, -182.9423, -122.9313,
         -245.8897,  -87.1143, -140.5741, -219.7802],
        [-223.6241, -108.2994, -230.9110, -201.8421, -157.5674, -136.5115,
         -180.7468, -107.2048, -227.3546, -285.5141],
        [-226.4874, -101.3004, -245.4319, -185.3739, -190.3146, -142.2153,
         -273.5862, -101.0410, -261.2281, -306.3717],
        [-151.2530,  -97.4268, -197.5811, -160.5764, -153.7173, -134.9987,
         -149.1485,  -98.0079, -156.0729, -206.6924],
        [-159.0162,  -77.9407, -224.7824, -144.6391, -178.3273, -190.9086,
         -152.3918,  -77.7679, -111.3031, -194.5852],
        [-187.9678,  -80.6179, -324.3092, -177.7108, -245.9505, -236.7465,
         -330.5939,  -79.0713, -328.5526, -147.0907],
        [-209.4873,  -95.0616, -333.1018, -208.5009, -140.2854, -124.6497,
         -189.8206,  -97.3593, -235.9101, -408.6098],
        [-149.4906,  -84.6891, -359.2938, -185.9259, -223.0973, -191.5558,
         -207.8119,  -85.5100, -223.3220, -223.5761],
        [-151.9225,  -81.8820, -310.1665, -198.3195, -214.5814, -196.9252,
         -224.1736,  -82.8910, -229.6676, -223.8177],
        [-222.8252, -117.6871, -207.2556, -140.1897, -228.1983, -172.7212,
         -352.7805, -118.7820, -217.3134, -190.8342],
        [-256.7337,  -91.6700, -193.4986, -193.1098, -390.3590, -142.3697,
         -278.9664,  -81.7105, -663.4983, -206.8276],
        [-187.4327,  -93.8845, -208.9526, -147.7736, -118.7956, -142.3816,
         -174.0429,  -94.7693, -203.3028, -198.1444],
        [-169.4206,  -85.4749, -370.1963, -205.3009, -276.3119, -210.4090,
         -279.7670,  -83.1115, -321.9343, -240.6085],
        [-130.3520,  -78.2582, -139.7027, -130.6935, -147.9837, -140.1112,
         -165.9398,  -81.4300, -125.2666, -167.4106],
        [-148.0492,  -96.0797, -173.4776, -136.7144, -128.9017, -167.9742,
         -152.8108,  -95.5047, -190.2735, -197.6867],
        [-204.7229,  -86.4831, -180.7059, -179.2285, -285.1131, -120.2297,
         -257.8649,  -81.7413, -544.4944, -229.0837],
        [-156.8028,  -72.5017, -220.2304, -156.8779, -169.2693, -166.6256,
         -101.4864,  -82.6765,  -77.2395, -229.5331],
        [-222.6703, -105.4447, -216.4786, -125.1613, -192.1170, -175.2939,
         -283.3384, -103.6581, -208.9574, -211.7422],
        [-209.1853,  -76.7290, -200.2220, -181.2367, -242.1838, -114.2219,
         -201.2557,  -75.9002, -414.8915, -277.2637],
        [-199.0136, -100.0156, -160.5647, -152.9506, -170.2144, -172.6942,
         -310.2397, -110.7212, -158.5666, -190.8455],
        [-234.5437, -121.1360, -232.0025, -162.9592, -170.5114, -141.0990,
         -251.9883, -120.9919, -287.4516, -248.0425],
        [-144.9756,  -80.5585, -222.8404, -124.6097, -179.3713, -161.8507,
         -150.7675,  -78.0479, -231.1037, -257.6938],
        [-191.1351,  -96.5224, -317.6041, -140.9188, -236.7210, -185.5332,
         -224.0291,  -97.1737, -320.5616, -250.3478],
        [-145.1733,  -70.3480, -242.0975, -125.4347, -201.1915, -152.5925,
         -142.6530,  -68.3675, -195.6721, -270.6101],
        [-197.0429, -104.1224, -304.4647, -161.8498, -257.6133, -177.3592,
         -221.6085,  -96.3251, -419.2679, -245.8960],
        [ -84.8878,  -50.7509, -182.1348, -131.6731, -104.8832, -158.0858,
          -46.0930,  -52.5151,  -66.6003, -262.1992],
        [-108.8174,  -46.0144, -207.8066, -151.3585,  -93.5438, -110.1722,
          -43.0588,  -47.0900,  -51.8295, -248.8625],
        [-101.3734,  -46.2658, -152.4307, -129.4233,  -85.3560, -156.0735,
          -43.4608,  -47.4620,  -60.5431, -237.0825],
        [-206.4458,  -98.1103, -379.8922, -225.1378, -191.6555, -148.1407,
         -234.7695, -101.4858, -222.0850, -358.1754],
        [-223.6941, -111.1014, -229.0400, -136.6600, -220.3186, -206.8554,
         -331.6769, -110.2549, -205.1671, -188.1833],
        [ -84.8091,  -52.0566, -226.9308, -138.2958, -116.3572, -152.2428,
          -48.0857,  -52.6489,  -83.2381, -256.3506],
        [-263.4832, -106.8476, -215.3556, -192.8641, -264.9235, -228.6798,
         -413.2106, -110.9003, -210.6227, -260.8717],
        [ -82.2010,  -50.9659, -198.4255, -130.5988, -142.6599, -177.5396,
          -48.1068,  -51.2649,  -75.0878, -243.6513]], device='cuda:0',
       grad_fn=<SumBackward1>)
=============================================================================================
Encoder Loss (Training) = Normal(loc: torch.Size([91, 10, 5]), scale: torch.Size([91, 10, 5]))
=============================================================================================
Decoder Loss (Test) = tensor([[-232.3058, -103.7233, -224.1168, -189.5050, -224.5157, -175.0105,
         -297.9439, -112.8672, -200.3987, -252.3368],
        [-115.2162,  -56.5309, -203.3743, -116.1673, -135.1172, -140.2449,
          -92.7648,  -53.5228, -126.4092, -217.2768],
        [-118.2273,  -78.8908, -166.9816, -116.2418, -113.5829, -140.4962,
          -99.9161,  -78.6756, -154.7062, -182.0981],
        [-145.7771,  -71.6124, -336.7245, -127.5000, -212.2644, -197.9637,
         -169.8524,  -68.4832, -194.2137, -220.4244],
        [-165.6052,  -95.1041, -553.0287, -218.9845, -296.6495, -238.2614,
         -253.7492,  -93.2070, -381.6411, -330.9340],
        [-265.4890,  -95.5895, -183.4549, -140.7295, -240.1339, -160.3752,
         -339.6121, -100.6230, -177.1975, -236.5182],
        [ -88.3087,  -51.2707, -197.7511, -135.3031, -113.2540, -160.1602,
          -46.7096,  -51.9617,  -76.5039, -249.6200]], device='cuda:0')
=============================================================================================
Encoder Loss (Test) = Normal(loc: torch.Size([7, 10, 5]), scale: torch.Size([7, 10, 5]))
=============================================================================================
