Dataset: USPS
--------------------------------------------
Model Name: MMVAE_random_seed_100_Latent_dim_5_Hard_Optimization_Beta_0.1_USPS_dataset
==================================================================
MMVAE_random_seed_100_Latent_dim_5_Hard_Optimization_Beta_0.1_USPS_dataset Part:
==================================================================
VAE Part:
==================================================================
Random Seed = 100
--------------------------------------------
Device = cuda:1
--------------------------------------------
Number of Epochs = 2000
--------------------------------------------
Learning Rate = 0.0001
--------------------------------------------
Step Size = 20
--------------------------------------------
Input Dimension = 256
--------------------------------------------
Encoder Hidden Dimension 1 = 500
--------------------------------------------
Encoder Hidden Dimension 2 = 500
--------------------------------------------
Encoder Hidden Dimension 3 = 2000
--------------------------------------------
Latent Dimension = 5
--------------------------------------------
Decoder Hidden Layer 1 = 2000
--------------------------------------------
Decoder Hidden Layer 2 = 500
--------------------------------------------
Decoder Hidden Layer 3 = 500
--------------------------------------------
Output Dimension = 256
--------------------------------------------
Weight Decay = 1e-05
--------------------------------------------
Batch Size (Training) = 100
--------------------------------------------
Batch Size (Test) = 100
--------------------------------------------
gamma = 0.9
--------------------------------------------
beta_1 = 0.1
==================================================================

GMM Part:
==================================================================
Number of Components= 10
--------------------------------------------
Covariance Matrix= full
--------------------------------------------
Number of Iterations= 20
--------------------------------------------
Epsilon = 1e-10
--------------------------------------------
Precision = 28
==================================================================

Early Stopping:
--------------------------------------------
Maximum Patience = 2001
--------------------------------------------
Best Test Loss = inf
--------------------------------------------
Patience Counters = 0
==================================================================

Loss Functions:
==================================================================
Decoder Loss (Training) = tensor([[ -91.4809, -104.8196,  -89.7993,  -89.3441,  -85.4758, -112.7857,
         -105.4800,  -85.8585,  -93.1027, -104.4633],
        [ -92.9474,  -96.9978,  -93.1741,  -92.8196,  -92.7851,  -93.6184,
          -98.4008, -104.2658,  -97.9370, -101.2798],
        [ -99.5348, -103.8460,  -99.9014,  -99.3215,  -99.2559, -101.7915,
         -107.7934, -105.6435, -104.1220, -117.1637],
        [ -79.9911,  -90.5138,  -80.1173,  -80.1729,  -79.9394,  -89.0718,
          -93.0738,  -94.7257,  -84.8643,  -94.4475],
        [ -71.3484, -100.8995,  -73.0470,  -73.0490,  -76.8584,  -98.7953,
          -97.8165,  -80.7901,  -75.2150,  -99.6831],
        [-108.0214, -131.6939, -107.4099, -108.9931, -107.5267, -134.1748,
         -139.6785, -133.2252, -120.0043, -145.7417],
        [ -90.8543,  -91.9343,  -91.0552,  -90.4289,  -90.4873,  -92.3829,
          -93.4964,  -94.8410,  -95.1523, -100.3211],
        [-108.8002, -128.2275, -108.2548, -107.7603, -107.8939, -131.5760,
         -148.1748, -116.5573, -129.1208, -161.1857],
        [ -58.7093,  -78.7958,  -58.7485,  -58.7135,  -59.5427,  -83.9054,
          -78.6258,  -65.1292,  -59.1914,  -80.6101],
        [ -87.1807, -109.6809,  -86.4423,  -87.5447,  -85.8002, -109.2441,
         -111.6351,  -87.8160,  -86.0293, -115.2280],
        [-102.3251, -103.0881, -102.8292, -100.8967, -100.7066, -102.9536,
         -106.1809, -103.4008, -108.8510, -118.0436],
        [ -97.9720, -121.4398,  -97.9836,  -98.5529,  -97.9936, -127.4269,
         -129.8764, -105.5862, -104.0742, -136.6369],
        [ -98.5742, -103.6801,  -98.8122,  -98.4859,  -98.4198, -101.8789,
         -104.9674, -106.5433, -106.0645, -113.5726],
        [ -67.3755,  -78.2793,  -66.2306,  -66.9252,  -71.1364,  -79.0368,
          -78.7865,  -68.1794,  -67.0839,  -78.4330],
        [-116.5838, -115.0987, -115.9384, -113.8333, -111.2364, -116.4503,
         -117.4894, -118.2736, -144.3927, -116.0305],
        [ -94.6291, -119.7066,  -94.6426,  -96.9723,  -94.7778, -119.8424,
         -124.4004, -121.4021, -102.2991, -128.0154],
        [ -37.9921,  -70.9641,  -38.2156,  -38.3679,  -38.7432,  -71.5831,
          -72.5608,  -39.0239,  -38.1142,  -75.3521],
        [ -76.6821,  -93.8692,  -77.0351,  -76.7309,  -76.9568,  -86.0461,
          -91.8567,  -87.3678,  -82.3016,  -96.1787],
        [ -67.8210,  -86.3830,  -67.8518,  -68.1322,  -69.6603,  -84.7748,
          -84.3324,  -73.3296,  -68.3955,  -85.0967],
        [ -40.1815,  -71.1453,  -40.2875,  -40.4652,  -40.5587,  -70.7370,
          -72.7415,  -41.4209,  -40.1133,  -75.8302],
        [ -82.9473,  -86.3804,  -82.9753,  -83.0973,  -82.9934,  -85.2804,
          -90.2444,  -89.4245,  -84.9165,  -92.2259],
        [ -76.9532,  -86.8380,  -77.0066,  -77.1319,  -84.1689,  -85.9813,
          -87.3270,  -94.0991,  -77.6255,  -87.1168],
        [-117.7749, -141.4812, -114.5509, -118.2153, -112.6622, -137.2315,
         -150.6620, -127.0504, -135.1189, -151.1840],
        [-105.4390, -107.2843, -106.7231, -105.6688, -121.1979, -105.4307,
         -114.6829, -121.8562, -113.8112, -113.7028],
        [ -54.4266,  -81.4124,  -54.6820,  -54.4462,  -54.6663,  -86.7770,
          -79.0159,  -60.2073,  -54.4946,  -83.7500],
        [ -98.6893, -100.4896,  -98.7493,  -98.9424,  -98.0388, -100.2888,
         -100.8454, -117.1014, -103.0594, -101.6164],
        [ -63.2796,  -96.5393,  -65.1999,  -63.5253,  -67.0700, -111.4240,
          -98.3902,  -74.6348,  -64.5945,  -89.6463],
        [ -47.0563, -108.3771,  -47.3965,  -46.9719,  -47.0175, -101.9068,
         -101.4797,  -51.4126,  -46.9669, -104.2124],
        [-109.2858, -129.1406, -103.1073, -107.7881, -100.9698, -141.8222,
         -125.8763, -118.6179, -116.9905, -135.2457],
        [ -73.9012,  -85.2332,  -73.4421,  -73.8330,  -73.7535,  -86.8992,
          -93.8775,  -82.0007,  -74.8565, -101.9858],
        [-100.5818, -116.3631, -101.5943, -100.3355, -101.7132, -116.5071,
         -116.0037, -130.5186, -102.0112, -117.2195],
        [ -85.0131,  -98.6694,  -85.3454,  -85.1267,  -84.9767,  -92.3248,
          -96.7307,  -97.0100,  -92.0891, -101.5528],
        [-101.5200, -121.6849, -101.4867, -101.4129, -101.2208, -122.1043,
         -126.0948, -115.3047, -103.3249, -134.5945],
        [ -43.8763,  -89.2528,  -44.1683,  -43.9596,  -44.1764,  -86.0589,
          -86.9023,  -46.1867,  -44.0939,  -91.6711],
        [ -76.7757,  -91.5512,  -76.6455,  -76.9602,  -76.6151,  -90.2724,
          -93.3903,  -82.0211,  -76.8787, -102.0253],
        [ -70.3331,  -84.0405,  -70.3134,  -70.2707,  -72.4598,  -84.2777,
          -85.3902,  -79.1997,  -70.5722,  -84.4874],
        [ -38.8580,  -71.4917,  -38.8397,  -38.9812,  -39.2599,  -72.5437,
          -73.0045,  -39.8926,  -38.7205,  -78.0654],
        [ -62.2555, -100.5737,  -64.3820,  -62.4354,  -66.0155, -114.5163,
         -104.3976,  -68.4895,  -62.9438,  -97.9259],
        [ -88.3263,  -96.1097,  -88.2466,  -89.4781,  -88.6496,  -99.0378,
          -98.6793,  -98.7142,  -90.7829, -102.2704],
        [-119.9480, -128.6805, -119.9084, -119.6366, -118.8850, -127.5677,
         -128.0516, -142.3573, -121.9068, -128.4649],
        [-121.7517, -126.7049, -121.5651, -123.6957, -121.6078, -127.8734,
         -127.3986, -146.3050, -130.2812, -127.7690],
        [-102.8641, -104.5424, -102.5607, -101.7018, -102.0695, -103.8654,
         -105.7528, -103.8591, -105.0182, -113.7251],
        [ -69.2232,  -91.9700,  -69.3161,  -69.4113,  -71.2945,  -87.2738,
          -94.5200,  -80.4962,  -70.8595,  -99.4145],
        [-120.3352, -129.7523, -120.5139, -120.8962, -120.2745, -135.7295,
         -134.0223, -137.3230, -128.6207, -137.7179],
        [ -85.6293,  -91.0537,  -85.7956,  -85.7166,  -85.7725,  -91.3287,
          -94.9090,  -98.6074,  -89.2388,  -99.6334],
        [ -97.8481,  -99.5911,  -97.9374,  -97.6476,  -97.4682,  -97.9238,
         -101.8429, -104.1958, -100.0297, -110.8745],
        [ -69.4337,  -87.5531,  -69.8403,  -70.5364,  -74.4385,  -84.6499,
          -84.6291,  -69.4944,  -72.1411,  -84.4915],
        [ -87.0381, -107.7890,  -87.0159,  -87.1799,  -87.0716,  -97.6325,
         -100.8284,  -99.8402,  -89.2607, -103.6181],
        [ -72.5492, -103.9958,  -72.3956,  -72.7982,  -72.9024, -106.4819,
         -102.2148,  -78.4546,  -72.8286, -103.4096],
        [ -81.5294,  -91.1254,  -81.8063,  -81.9072,  -81.9700,  -93.1793,
          -90.6101,  -90.3712,  -81.9779,  -92.4070],
        [ -36.7725,  -63.0617,  -36.7720,  -37.1580,  -37.7002,  -64.6234,
          -65.6509,  -37.4091,  -36.5071,  -69.5506],
        [ -82.6923,  -99.0918,  -82.3314,  -82.4941,  -82.5504, -102.3154,
         -100.4700, -100.9679,  -82.8112, -102.4127],
        [ -81.6672, -104.9189,  -81.7888,  -81.5649,  -81.6821,  -88.9280,
          -92.9218,  -97.9742,  -89.6678,  -93.3164],
        [-116.6107, -138.9234, -116.7707, -116.6400, -116.0487, -139.8265,
         -146.9232, -148.1591, -124.0545, -153.5413],
        [ -96.3612,  -98.1022,  -96.5796,  -95.3210,  -95.1942,  -97.5510,
         -100.3975, -100.2001, -101.1688, -111.0032],
        [-109.2136, -127.9263, -105.7682, -108.7714, -103.6658, -131.7462,
         -117.5426, -111.8671, -114.1564, -119.8393],
        [-104.8091, -104.9551, -104.7107, -102.8987, -102.5341, -104.7820,
         -110.6129, -113.9428, -113.7728, -115.9175],
        [ -95.3205, -113.4518,  -95.3750,  -95.5587,  -95.3850, -113.8341,
         -110.0287, -113.2545,  -97.5593, -111.8521],
        [ -74.5188,  -84.1583,  -74.4936,  -74.0939,  -75.7421,  -84.7913,
          -85.6472,  -80.1990,  -74.1080,  -84.9579],
        [ -38.5655,  -71.6399,  -38.6902,  -38.5130,  -38.7641,  -73.0176,
          -73.3289,  -39.8459,  -38.3491,  -77.7666],
        [ -88.7498, -108.5801,  -88.6938,  -90.4135,  -88.4030, -110.0904,
         -117.0324, -109.2363,  -94.9648, -118.8987],
        [ -81.4939,  -89.1055,  -81.3447,  -80.8823,  -81.9371,  -88.2701,
          -89.5587,  -88.5227,  -83.1375,  -92.8924],
        [ -93.9040,  -97.4241,  -93.4857,  -93.4268,  -93.2119, -101.7609,
          -97.3251,  -94.0343,  -93.0202, -100.8490],
        [ -47.6848, -111.2860,  -48.2847,  -47.7792,  -47.7400, -104.7062,
         -103.4683,  -52.3890,  -47.6883, -104.3289],
        [ -95.2773,  -98.1906,  -95.2575,  -95.3703,  -95.3314,  -95.2132,
          -99.8918, -105.5269,  -98.8247, -103.3209],
        [ -72.7088,  -97.0189,  -72.0443,  -72.4740,  -72.6946, -102.9897,
          -98.1645,  -74.9551,  -72.3149,  -99.9585],
        [ -88.9026,  -95.6897,  -89.0087,  -88.7344,  -89.0528,  -98.0313,
         -101.3145,  -98.7745,  -89.1068, -108.1067],
        [-102.1426, -131.6642, -101.8607, -105.3902, -102.0101, -143.2433,
         -140.6520, -113.6490, -114.1451, -150.7793],
        [-106.0745, -160.2927, -106.0999, -106.2065, -106.4675, -141.0620,
         -146.9575, -113.3838, -110.2373, -162.7738],
        [-105.2843, -114.3137, -102.8570, -102.8019, -102.4146, -111.6072,
         -108.3172, -118.1806, -107.8817, -108.9665],
        [ -89.8418,  -96.5266,  -89.9559,  -89.9664,  -89.8620,  -96.2096,
          -98.6648, -122.8807,  -92.4921,  -99.8580],
        [ -81.4050,  -89.1003,  -81.2611,  -81.3022,  -81.3855,  -86.4807,
          -91.9035,  -94.1767,  -85.3487,  -93.8312],
        [ -93.8244,  -97.6482,  -94.1969,  -93.6719,  -93.7084,  -94.8933,
          -99.2410, -103.8687,  -97.4326, -106.7760],
        [ -80.8886, -108.4023,  -80.8813,  -80.8404,  -80.9499, -117.3878,
         -115.4564,  -84.8629,  -82.0566, -121.6817],
        [-112.4898, -113.4207, -112.3387, -112.0601, -112.1445, -113.5382,
         -115.3709, -141.6109, -114.0825, -114.0591],
        [ -47.9083, -105.0722,  -48.2536,  -47.8603,  -47.9980,  -99.1077,
          -98.0168,  -51.6266,  -47.9631, -101.4250],
        [ -48.7095,  -97.9396,  -48.9061,  -48.4666,  -48.7348,  -92.9849,
          -94.2524,  -53.4369,  -48.8221,  -96.0350],
        [ -66.5368,  -79.2116,  -66.1998,  -65.5359,  -68.0644,  -88.7957,
          -83.2419,  -72.2411,  -65.6085,  -80.5082],
        [-106.3386, -125.6198, -106.0456, -104.1809, -103.8706, -127.6279,
         -147.1141, -107.9011, -113.8702, -186.5726],
        [ -81.3519,  -93.0847,  -82.5305,  -81.2390,  -81.1120,  -85.9933,
          -90.7442,  -94.1807,  -88.9968,  -91.2947],
        [ -96.3407,  -97.6549,  -96.9076,  -97.1880,  -98.3191,  -96.9863,
          -99.8239, -102.2801, -102.1021,  -98.8830],
        [ -97.7924, -105.7401,  -97.7931,  -97.5588, -100.1323, -106.5725,
         -108.7225, -111.4686,  -99.7706, -108.5630],
        [ -80.9663, -101.7149,  -80.4947,  -84.6760,  -83.8875,  -99.6656,
          -98.6599,  -84.1183,  -85.4888,  -99.8237],
        [ -83.4590, -101.3979,  -83.7061,  -84.8920,  -91.0210, -102.2552,
         -101.5699,  -86.6763,  -86.7897, -101.3539],
        [ -47.5251,  -95.2268,  -48.2216,  -47.6524,  -47.9333,  -91.2529,
          -89.1825,  -51.3452,  -47.8358,  -91.6959],
        [ -84.2203, -116.3524,  -84.1514,  -84.2166,  -83.9931,  -97.6798,
          -99.0277,  -91.5807,  -86.9743, -101.8948],
        [-112.3359, -118.0044, -112.9415, -112.5899, -113.6784, -118.1482,
         -119.1001, -115.5157, -112.6146, -119.0138],
        [ -98.5614, -114.2364,  -97.2257,  -94.5553,  -94.4312, -126.7035,
         -121.3304,  -94.4305, -113.7809, -125.3738],
        [ -65.1213, -103.4862,  -64.5441,  -65.3581,  -65.2104, -111.8212,
         -105.1514,  -68.2066,  -65.4636, -116.6210],
        [-115.6150, -116.3115, -115.1896, -116.2697, -115.0459, -127.7767,
         -115.6094, -122.2884, -120.8638, -115.4436],
        [ -72.4680,  -88.6382,  -71.8478,  -71.9408,  -72.2315,  -87.1916,
          -87.2669,  -73.2977,  -71.7523,  -89.4785]], device='cuda:1',
       grad_fn=<SumBackward1>)
=============================================================================================
Encoder Loss (Training) = Normal(loc: torch.Size([91, 10, 5]), scale: torch.Size([91, 10, 5]))
=============================================================================================
Decoder Loss (Test) = tensor([[-108.5199, -112.4242, -108.6737, -103.7285, -104.2366, -118.6498,
         -106.4359, -104.0711, -123.4211, -110.7667],
        [ -52.9464,  -71.4936,  -52.9040,  -53.3425,  -55.6719,  -70.6591,
          -71.4274,  -54.1041,  -53.4016,  -72.1200],
        [ -75.5397,  -92.7897,  -75.2847,  -75.5971,  -75.3703,  -96.1992,
         -101.5816,  -83.3162,  -78.3811, -105.3675],
        [ -68.4552,  -93.7794,  -69.7368,  -68.9225,  -74.1777,  -91.9951,
          -92.3209,  -93.7208,  -69.3150,  -91.2240],
        [ -94.3905, -118.7702,  -95.8030,  -93.8641,  -98.6265, -129.5693,
         -106.6458,  -98.0343,  -94.4251, -106.8813],
        [ -96.5575, -101.5730,  -96.7653,  -96.0348,  -95.8835,  -96.8831,
         -105.1451, -104.9134, -104.9899, -111.1213],
        [ -46.6147, -104.4024,  -47.1563,  -46.7204,  -46.8868,  -99.2943,
          -99.3367,  -51.9690,  -46.5969,  -97.6637]], device='cuda:1')
=============================================================================================
Encoder Loss (Test) = Normal(loc: torch.Size([7, 10, 5]), scale: torch.Size([7, 10, 5]))
=============================================================================================
