Dataset: Digits
--------------------------------------------
Model Name: MMVAE_random_seed_30_Latent_dim_5_Soft_Optimization_Beta_0.1_Digits
==================================================================
MMVAE_random_seed_30_Latent_dim_5_Soft_Optimization_Beta_0.1_Digits Part:
==================================================================
VAE Part:
==================================================================
Random Seed = 30
--------------------------------------------
Device = cuda:0
--------------------------------------------
Number of Epochs = 1500
--------------------------------------------
Learning Rate = 0.0001
--------------------------------------------
Step Size = 20
--------------------------------------------
Input Dimension = 64
--------------------------------------------
Encoder Hidden Dimension 1 = 256
--------------------------------------------
Encoder Hidden Dimension 2 = 256
--------------------------------------------
Latent Dimension = 5
--------------------------------------------
Decoder Hidden Layer 1 = 256
--------------------------------------------
Decoder Hidden Layer 2 = 256
--------------------------------------------
Output Dimension = 64
--------------------------------------------
Weight Decay = 1e-05
--------------------------------------------
Batch Size (Training) = 50
--------------------------------------------
Batch Size (Test) = 50
--------------------------------------------
gamma = 0.9
--------------------------------------------
beta_1 = 0.1
==================================================================

GMM Part:
==================================================================
Number of Components= 10
--------------------------------------------
Covariance Matrix= full
--------------------------------------------
Number of Iterations= 20
--------------------------------------------
Epsilon = 1e-10
--------------------------------------------
Precision = 28
==================================================================

Early Stopping:
--------------------------------------------
Maximum Patience = 1501
--------------------------------------------
Best Test Loss = inf
--------------------------------------------
Patience Counters = 0
==================================================================

Loss Functions:
==================================================================
Decoder Loss (Training) = tensor([[-15.2603, -18.9568, -15.6704, -15.6437, -16.1917, -16.0147, -23.2171,
         -14.8482, -17.3759, -18.5122],
        [-17.6498, -18.8893, -17.9915, -18.1516, -17.9533, -17.4508, -18.0844,
         -17.7723, -18.2479, -17.3607],
        [-15.0045, -14.0005, -13.9697, -15.4678, -14.0888, -14.6273, -19.5984,
         -18.4523, -19.2825, -23.0376],
        [-17.2336, -15.1201, -18.1969, -15.4466, -15.9481, -17.3253, -16.4144,
         -15.7375, -15.7498, -16.0760],
        [-15.6009, -13.7332, -12.4542, -17.9237, -11.8954, -13.6932, -23.8861,
         -14.4579, -20.6971, -22.0363],
        [-22.3563, -19.3521, -24.8054, -19.7953, -23.6373, -26.8895, -20.3647,
         -19.6718, -19.5501, -19.1898],
        [-19.2767, -20.3037, -20.9565, -18.7831, -20.0358, -20.5668, -19.5337,
         -18.8470, -19.1463, -18.7490],
        [-20.9738, -18.0584, -28.5067, -18.8864, -25.5081, -26.3057, -18.8594,
         -18.9826, -18.3704, -17.8986],
        [-21.9114, -22.5714, -21.7201, -21.5619, -21.6012, -22.6847, -21.6639,
         -21.3736, -21.4132, -21.5413],
        [-22.4030, -20.6997, -24.8567, -21.3325, -24.9733, -28.9185, -20.8727,
         -20.7880, -21.3919, -20.1402],
        [-16.5563, -19.1678, -16.9265, -16.6791, -16.6592, -17.0952, -20.1517,
         -16.5979, -16.8150, -17.0046],
        [-20.7474, -17.9333, -21.1495, -20.0005, -20.8023, -23.4659, -22.0984,
         -18.1260, -21.1144, -21.0118],
        [-14.7926, -14.8494, -14.5828, -14.9572, -14.6992, -15.4086, -17.3888,
         -17.2263, -16.8430, -17.6351],
        [-21.2585, -21.2947, -21.5614, -21.6167, -21.7663, -21.6106, -22.1965,
         -21.8602, -21.9166, -21.2632],
        [-21.7398, -22.2189, -21.4665, -20.6332, -22.1170, -21.3038, -20.2368,
         -23.2797, -20.5498, -22.1911],
        [-16.7002, -16.3546, -16.5092, -16.8881, -17.7496, -19.5576, -17.1563,
         -17.3701, -17.6543, -17.6154],
        [-18.7968, -17.4221, -17.1684, -17.3151, -17.5844, -17.5494, -17.5463,
         -17.6310, -18.0754, -17.9638],
        [-14.9108, -17.1602, -17.0051, -15.6687, -17.3780, -17.1325, -22.0793,
         -15.0721, -17.6682, -16.3380],
        [-21.6657, -21.9245, -22.3942, -22.4634, -22.3799, -22.7585, -24.7499,
         -21.5939, -22.9309, -22.7193],
        [-25.4717, -24.4191, -24.3821, -24.2628, -24.3577, -26.0775, -25.4969,
         -24.8801, -24.5820, -26.8446],
        [-16.6279, -16.4674, -18.3589, -16.5166, -17.8258, -17.6609, -18.0113,
         -16.8780, -19.0235, -16.3558],
        [-15.5866, -16.8974, -15.9472, -15.7577, -15.9917, -17.4740, -18.5139,
         -16.2935, -17.0067, -17.2675],
        [-20.3592, -20.8083, -20.8120, -20.8384, -21.3821, -21.5868, -20.3386,
         -21.0395, -20.9206, -21.5492],
        [-17.1474, -14.7520, -16.2183, -16.4834, -16.2135, -17.1602, -19.9872,
         -15.3491, -18.0656, -19.4692],
        [-25.8746, -27.9096, -25.2270, -26.5567, -28.0106, -24.6525, -23.9572,
         -28.4718, -25.2478, -30.7946],
        [-24.1201, -23.1867, -25.5267, -22.9268, -24.1379, -24.5580, -22.4384,
         -23.0930, -23.1972, -22.7992],
        [-20.7007, -18.5807, -18.5104, -19.0227, -20.0003, -18.4698, -25.4358,
         -22.8546, -22.6929, -23.5685]], device='cuda:0',
       grad_fn=<SumBackward1>)
=============================================================================================
Encoder Loss (Training) = Normal(loc: torch.Size([27, 10, 5]), scale: torch.Size([27, 10, 5]))
=============================================================================================
Decoder Loss (Test) = tensor([[-18.0991, -21.1692, -18.1250, -18.9277, -18.7803, -19.4578, -27.6830,
         -18.9693, -19.9608, -32.1378],
        [-23.1756, -22.9728, -21.9810, -22.4818, -21.5554, -24.1446, -27.0144,
         -22.9648, -21.6451, -31.3080],
        [-16.9647, -19.0835, -17.2735, -17.1262, -16.8993, -17.1343, -22.0963,
         -16.8654, -18.1372, -19.0729],
        [-22.5702, -19.6908, -20.4142, -20.8067, -19.9146, -21.2688, -21.2546,
         -20.9696, -22.0020, -20.4953],
        [-23.0960, -22.5607, -25.3537, -22.4052, -26.8972, -28.0659, -21.3860,
         -21.6377, -21.9530, -21.5222],
        [-21.0017, -17.1403, -17.9169, -19.2542, -17.5079, -18.6293, -20.5686,
         -19.0414, -20.0131, -20.7319],
        [-23.8311, -20.1114, -20.6528, -22.1188, -20.3116, -21.0422, -22.7939,
         -22.2474, -22.4200, -21.8519],
        [-23.5781, -22.1491, -22.6605, -22.2974, -24.0282, -19.8181, -21.3982,
         -22.5430, -22.1209, -20.9116],
        [-16.6488, -18.6214, -16.0351, -17.1682, -16.5091, -16.6417, -28.2639,
         -15.9257, -20.1550, -20.5889],
        [-20.0933, -17.9573, -20.8014, -18.5140, -20.9561, -22.0080, -18.2628,
         -18.7308, -18.5879, -17.9068],
        [-22.3801, -18.8195, -23.8864, -19.7797, -23.2482, -22.2316, -19.2355,
         -19.1159, -19.1358, -18.8538],
        [-17.0566, -17.2311, -16.3726, -16.3429, -17.2367, -18.0596, -20.3753,
         -16.7084, -16.2091, -24.9777],
        [-19.7308, -20.7669, -20.9390, -19.6505, -21.4375, -21.2456, -19.8014,
         -19.4282, -19.2191, -19.0966],
        [-20.3592, -20.7184, -20.4765, -20.1115, -20.7307, -21.7558, -21.1024,
         -20.0405, -19.9826, -20.3460],
        [-16.5216, -17.7367, -16.2667, -16.5733, -17.0200, -16.7920, -20.8143,
         -16.8284, -16.5880, -22.4502],
        [-18.4944, -18.5173, -18.3697, -17.7965, -18.2852, -19.9250, -17.4964,
         -17.7023, -17.7535, -17.6574],
        [-19.1154, -19.0106, -19.3990, -18.7589, -18.9664, -19.1939, -18.8285,
         -19.7708, -18.7569, -19.6095],
        [-18.2007, -17.9282, -18.2138, -17.8871, -18.4785, -19.8335, -18.1729,
         -17.8718, -18.0614, -18.5397],
        [-20.9892, -19.9278, -20.3268, -19.9738, -20.9640, -22.5773, -19.4012,
         -20.1289, -19.9781, -19.6511],
        [-25.4075, -24.8885, -25.8778, -25.0857, -27.7368, -30.3832, -24.1649,
         -24.2358, -24.2724, -24.9589]], device='cuda:0')
=============================================================================================
Encoder Loss (Test) = Normal(loc: torch.Size([20, 10, 5]), scale: torch.Size([20, 10, 5]))
=============================================================================================
